# Updating...
# Video Object Segmentation: VOS Paper List

## Benchmark Results

- **DAVIS2017-Val**

|Tracker| OL |J&F Mean|Speed(FPS)|Paper/Code|
|:-----:|:--:|:-----:|:-----:|:-:|
|STM    |    | 84.3  |  6.25 |[Paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.pdf)/[Code](https://github.com/seoungwugoh/STM)|
|PReMVOS   | | 77.8  |  0.01 |[Paper](https://arxiv.org/abs/1807.09190)/[Code](https://github.com/JonathonLuiten/PReMVOS)|
|FRTM-VOS  | | 76.7  | 21.9  |[Paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Robinson_Learning_Fast_and_Robust_Target_Models_for_Video_Object_Segmentation_CVPR_2020_paper.pdf)/[Code](https://github.com/andr345/frtm-vos)|
|TAN-DTTM  | | 75.9  |  7.1  |[Paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Fast_Video_Object_Segmentation_With_Temporal_Aggregation_Network_and_Dynamic_CVPR_2020_paper.pdf)/[Code](https://github.com/XUHUAKing)|
|TVOS      | | 72.3  | 37    |[Paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_A_Transductive_Approach_for_Video_Object_Segmentation_CVPR_2020_paper.pdf)/[Code](https://github.com/microsoft/transductive-vos.pytorch)|
|SAT       | | 72.3  | 39    |[Paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_State-Aware_Tracker_for_Real-Time_Video_Object_Segmentation_CVPR_2020_paper.pdf)/[Code]()|
|FEELVOS   | | 71.5  |  2.20 |[Paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Voigtlaender_FEELVOS_Fast_End-To-End_Embedding_Learning_for_Video_Object_Segmentation_CVPR_2019_paper.pdf)/[Code](https://github.com/kim-younghan/FEELVOS)|
|AGAME     | | 70.0  | 14.3  |[Paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.pdf)/[Code](https://github.com/joakimjohnander/agame-vos)|
|Dyenet    | | 69.1  |  2.40 |[Paper]()/[Code]()|
|OSVOS-S   |Y| 68.0  |  0.22 |[Paper]()/[Code]()|
|RGMP      | | 66.7  |  7.7  |[Paper]()/[Code]()|
|RANet     | | 65.7  | 30    |[Paper]()/[Code]()|
|STCNN     | | 61.7  |  0.25 |[Paper]()/[Code]()|
|D3S       | | 60.8  | 25    |[Paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.pdf)/[Code](https://github.com/joakimjohnander/agame-vos)|
|OSVOS     |Y| 60.3  |  0.22 |[Paper]()/[Code]()|
|FAVOS     | | 58.2  |  0.56 |[Paper]()/[Code]()|
|SiamMask  | | 56.4  | 35    |[Paper]()/[Code]()|


## Paper List

**CVPR2020**

- **TVOS:** Zhang, Yizhuo and Wu, Zhirong and Peng, Houwen and Lin, Stephen.<br>
"A Transductive Approach for Video Object Segmentation." [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_A_Transductive_Approach_for_Video_Object_Segmentation_CVPR_2020_paper.pdf) [[Code]](https://github.com/microsoft/transductive-vos.pytorch)

- **FRTM-VOS:** Robinson, Andreas and Lawin, Felix Jaremo and Danelljan, Martin and Khan, Fahad Shahbaz and Felsberg, Michael.<br>
"Learning Fast and Robust Target Models for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Robinson_Learning_Fast_and_Robust_Target_Models_for_Video_Object_Segmentation_CVPR_2020_paper.pdf) [[Code]](https://github.com/andr345/frtm-vos)

- **TAN-DTTM:** Huang, Xuhua and Xu, Jiarui and Tai, Yu-Wing and Tang, Chi-Keung.<br>
"Fast Video Object Segmentation With Temporal Aggregation Network and Dynamic Template Matching."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Fast_Video_Object_Segmentation_With_Temporal_Aggregation_Network_and_Dynamic_CVPR_2020_paper.pdf) [[Code]](https://github.com/XUHUAKing)

- **MuG:** Lu, Xiankai and Wang, Wenguan and Shen, Jianbing and Tai, Yu-Wing and Crandall, David J. and Hoi, Steven C. H..<br>
"Learning Video Object Segmentation From Unlabeled Videos."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Lu_Learning_Video_Object_Segmentation_From_Unlabeled_Videos_CVPR_2020_paper.pdf) [[Code]](https://github.com/carrierlxk/MuG)

- **SAT:** Chen, Xi and Li, Zuoxin and Yuan, Ye and Yu, Gang and Shen, Jianxin and Qi, Donglian.<br>
"State-Aware Tracker for Real-Time Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_State-Aware_Tracker_for_Real-Time_Video_Object_Segmentation_CVPR_2020_paper.pdf)

- **MA-Net:** Miao, Jiaxu and Wei, Yunchao and Yang, Yi.<br>
"Memory Aggregation Networks for Efficient Interactive Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Miao_Memory_Aggregation_Networks_for_Efficient_Interactive_Video_Object_Segmentation_CVPR_2020_paper.pdf)

- **D3S:** Lukezic, Alan and Matas, Jiri and Kristan, Matej.<bar>
"D3S - A Discriminative Single Shot Segmentation Tracker."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Lukezic_D3S_-_A_Discriminative_Single_Shot_Segmentation_Tracker_CVPR_2020_paper.pdf) [[Code]](https://github.com/alanlukezic/d3s)


**ICCV2019**

- **AD-Net** Yang, Zhao and Wang, Qiang and Bertinetto, Luca and Hu, Weiming and Bai, Song and Torr, Philip H. S.<bar>
"Anchor Diffusion for Unsupervised Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Anchor_Diffusion_for_Unsupervised_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/yz93/anchor-diff-VOS)

- **STM:** Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon Joo.<bar>
"Video Object Segmentation Using Space-Time Memory Networks."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.pdf) [[Code]](https://github.com/seoungwugoh/STM)

- **AGNN:** Wang, Wenguan and Lu, Xiankai and Shen, Jianbing and Crandall, David J. and Shao, Ling.<bar>
"Zero-Shot Video Object Segmentation via Attentive Graph Neural Networks."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Zero-Shot_Video_Object_Segmentation_via_Attentive_Graph_Neural_Networks_ICCV_2019_paper.pdf) [[Code]](https://github.com/carrierlxk/AGNN)

- **DMM-Net:** Zeng, Xiaohui and Liao, Renjie and Gu, Li and Xiong, Yuwen and Fidler, Sanja and Urtasun, Raquel.<bar>
"DMM-Net: Differentiable Mask-Matching Network for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Zeng_DMM-Net_Differentiable_Mask-Matching_Network_for_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/ZENGXH/DMM_Net)

- **AGSS-VOS:** Lin, Huaijia and Qi, Xiaojuan and Jia, Jiaya.<bar>
"AGSS-VOS: Attention Guided Single-Shot Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Lin_AGSS-VOS_Attention_Guided_Single-Shot_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/Jia-Research-Lab/AGSS-VOS)

- **RANet:** Wang, Ziqin and Xu, Jun and Liu, Li and Zhu, Fan and Shao, Ling.<bar>
"RANet: Ranking Attention Network for Fast Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_RANet_Ranking_Attention_Network_for_Fast_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/Storife/RANet)

- **DTN:** Zhang, Lu and Lin, Zhe and Zhang, Jianming and Lu, Huchuan and He, You.<bar>
"Fast Video Object Segmentation via Dynamic Targeting Network."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Fast_Video_Object_Segmentation_via_Dynamic_Targeting_Network_ICCV_2019_paper.pdf) [[Code]](https://github.com/zhangludl/Code-for-DTN)

- **CapsuleVOS:** Duarte, Kevin and Rawat, Yogesh S. and Shah, Mubarak.<bar>
"CapsuleVOS: Semi-Supervised Video Object Segmentation Using Capsule Routing."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Duarte_CapsuleVOS_Semi-Supervised_Video_Object_Segmentation_Using_Capsule_Routing_ICCV_2019_paper.pdf) [[Code]](https://github.com/KevinDuarte/CapsuleVOS)

**CVPR2019**

- **MHP-VOS:** Xu, Shuangjie and Liu, Daizong and Bao, Linchao and Liu, Wei and Zhou, Pan.<bar>
"MHP-VOS: Multiple Hypotheses Propagation for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_MHP-VOS_Multiple_Hypotheses_Propagation_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/shuangjiexu/MHP-VOS)

- **STCNN:** Xu, Kai and Wen, Longyin and Li, Guorong and Bo, Liefeng and Huang, Qingming.<bar>
"Spatiotemporal CNN for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Spatiotemporal_CNN_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/longyin880815/STCNN)

- **AGS:** Wang, Wenguan and Song, Hongmei and Zhao, Shuyang and Shen, Jianbing and Zhao, Sanyuan and Hoi, Steven C. H. and Ling, Haibin.<bar>
"Learning Unsupervised Video Object Segmentation Through Visual Attention."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Learning_Unsupervised_Video_Object_Segmentation_Through_Visual_Attention_CVPR_2019_paper.pdf) [[Code]](https://github.com/wenguanwang/AGS)

- **COSNet:** Lu, Xiankai and Wang, Wenguan and Ma, Chao and Shen, Jianbing and Shao, Ling and Porikli, Fatih.<bar>
"See More, Know More: Unsupervised Video Object Segmentation With Co-Attention Siamese Networks."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Lu_See_More_Know_More_Unsupervised_Video_Object_Segmentation_With_Co-Attention_CVPR_2019_paper.pdf) [[Code]](https://github.com/carrierlxk/COSNet)


- **IVS:** Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon Joo.<bar>
"Fast User-Guided Video Object Segmentation by Interaction-And-Propagation Networks."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Oh_Fast_User-Guided_Video_Object_Segmentation_by_Interaction-And-Propagation_Networks_CVPR_2019_paper.pdf) [[Code]](https://github.com/seoungwugoh/ivs-demo)

- **RVOS:** Ventura, Carles and Bellver, Miriam and Girbau, Andreu and Salvador, Amaia and Marques, Ferran and Giro-i-Nieto, Xavier.<bar>
"RVOS: End-To-End Recurrent Network for Video Object Segmentation." [[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Ventura_RVOS_End-To-End_Recurrent_Network_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/imatge-upc/rvos)

- **BubbleNets:** Griffin, Brent A. and Corso, Jason J.<bar>
"BubbleNets: Learning to Select the Guidance Frame in Video Object Segmentation by Deep Sorting Frames."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Griffin_BubbleNets_Learning_to_Select_the_Guidance_Frame_in_Video_Object_CVPR_2019_paper.pdf) [[Code]](https://github.com/griffbr/BubbleNets)

- **AGAME:** Johnander, Joakim and Danelljan, Martin and Brissman, Emil and Khan, Fahad Shahbaz and Felsberg, Michael.<bar>
"A Generative Appearance Model for End-To-End Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/joakimjohnander/agame-vos)

- **FEELVOS:** Voigtlaender, Paul and Chai, Yuning and Schroff, Florian and Adam, Hartwig and Leibe, Bastian and Chen, Liang-Chieh.<bar>
"FEELVOS: Fast End-To-End Embedding Learning for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Voigtlaender_FEELVOS_Fast_End-To-End_Embedding_Learning_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/kim-younghan/FEELVOS)


## Datasets

- **SAIL-VOS:** Hu, Yuan-Ting and Chen, Hong-Shuo and Hui, Kexin and Huang, Jia-Bin and Schwing, Alexander G.<bar>
"SAIL-VOS: Semantic Amodal Instance Level Video Object Segmentation - A Synthetic Dataset and Baselines." CVPR2019. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Hu_SAIL-VOS_Semantic_Amodal_Instance_Level_Video_Object_Segmentation_-_A_CVPR_2019_paper.pdf) [[website]](http://sailvos.web.illinois.edu/_site/index.html)

- **SegTrack v2:** Fuxin Li and Taeyoung Kim and Ahmad Humayun and David Tsai and James M. Rehg.<bar>
" Video Segmentation by Tracking Many Figure-Ground Segments."[[Paper]](https://web.engr.oregonstate.edu/~lif/SegTrack2/segtrack2_cameraready.pdf) [[website]](https://web.engr.oregonstate.edu/~lif/SegTrack2/dataset.html)

- **DAVIS Challenge:** "Densely Annotated Video Segmentation."[[website]](https://davischallenge.org/)
