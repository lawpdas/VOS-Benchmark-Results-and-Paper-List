# Updating ...

# Video Object Segmentation Paper List

## Benchmark Results

  <table width="1194" border="0" cellpadding="0" cellspacing="0" style='width:895.50pt;border-collapse:collapse;table-layout:fixed;'>
   <col width="136" class="xl65" style='mso-width-source:userset;mso-width-alt:3481;'/>
   <col width="57" span="3" class="xl66" style='mso-width-source:userset;mso-width-alt:1459;'/>
   <col width="57" span="3" class="xl67" style='mso-width-source:userset;mso-width-alt:1459;'/>
   <col width="57" span="3" class="xl66" style='mso-width-source:userset;mso-width-alt:1459;'/>
   <col width="57" span="4" class="xl68" style='mso-width-source:userset;mso-width-alt:1459;'/>
   <col width="42" class="xl68" style='mso-width-source:userset;mso-width-alt:1075;'/>
   <col width="57" class="xl69" style='mso-width-source:userset;mso-width-alt:1459;'/>
   <col width="109" span="240" class="xl65" style='mso-width-source:userset;mso-width-alt:2790;'/>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl70" height="66" width="136" rowspan="3" style='height:49.50pt;width:102.00pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>Tracker</td>
    <td class="xl71" width="171" colspan="3" style='width:128.25pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>DIVAS2017 val</td>
    <td class="xl76" width="171" colspan="3" style='width:128.25pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>DIVAS2017 test-dev</td>
    <td class="xl71" width="171" colspan="3" style='width:128.25pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>DIVAS2016 val</td>
    <td class="xl80" width="270" colspan="5" style='width:202.50pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>YouTube-VOS</td>
    <td class="xl83" width="57" rowspan="3" style='width:42.75pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>Speed (FPS)</td>
    <td class="xl70" width="109" rowspan="3" style='width:81.75pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>Paper</td>
    <td class="xl70" width="109" rowspan="3" style='width:81.75pt;border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>Code</td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl71" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>J</td>
    <td class="xl71" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>F</td>
    <td class="xl71" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>J&amp;F</td>
    <td class="xl76" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>J</td>
    <td class="xl76" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>F</td>
    <td class="xl76" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>J&amp;F</td>
    <td class="xl71" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>J</td>
    <td class="xl71" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>F</td>
    <td class="xl71" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>J&amp;F</td>
    <td class="xl80" rowspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>Overall</td>
    <td class="xl80" colspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>Seen</td>
    <td class="xl80" colspan="2" style='border-right:.5pt solid windowtext;border-bottom:.5pt solid windowtext;' x:str>Unseen</td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl80" x:str>J</td>
    <td class="xl80" x:str>F</td>
    <td class="xl80" x:str>J</td>
    <td class="xl80" x:str>F</td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>STM</td>
    <td class="xl75" x:num="81.700000000000003">81.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="79.200000000000003">79.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="84.299999999999997">84.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl75" x:num="81.700000000000003">81.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="79.200000000000003">79.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="84.299999999999997">84.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="79.400000000000006">79.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="79.700000000000003">79.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="84.200000000000003">84.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="72.799999999999997">72.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="80.900000000000006">80.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl85" x:num="6.25">6.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.pdf" target="_parent">ICCV2019</a></td>
    <td class="xl65"></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>PReMVOS</td>
    <td class="xl75" x:num="73.900000000000006">73.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="81.700000000000003">81.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="77.799999999999997">77.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="67.5">67.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="75.700000000000003">75.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="71.599999999999994">71.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="73.900000000000006">73.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="81.700000000000003">81.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="77.799999999999997">77.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="0.029999999999999999">0.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://arxiv.org/abs/1807.09190" target="_parent">ACCV2018</a></td>
    <td class="xl86" x:str><a href="https://github.com/JonathonLuiten/PReMVOS" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>FRTM-VOS</td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl75" x:num="76.700000000000003">76.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl75" x:num="83.5">83.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="21.899999999999999">21.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl87" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Robinson_Learning_Fast_and_Robust_Target_Models_for_Video_Object_Segmentation_CVPR_2020_paper.pdf" target="_parent">CVPR2020</a></td>
    <td class="xl86" x:str><a href="https://github.com/andr345/frtm-vos" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>DTTM-TAN</td>
    <td class="xl75" x:num="72.299999999999997">72.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="79.400000000000006">79.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="75.900000000000006">75.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="61.299999999999997">61.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="70.299999999999997">70.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="65.400000000000006">65.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl82" x:num="73.5">73.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="7.1399999999999997">7.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Fast_Video_Object_Segmentation_With_Temporal_Aggregation_Network_and_Dynamic_CVPR_2020_paper.pdf" target="_parent">CVPR2020</a></td>
    <td class="xl86" x:str><a href="https://xuhuaking.github.io/Fast-VOS-DTTM-TAN/" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>TVOS</td>
    <td class="xl75" x:num="69.900000000000006">69.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="74.700000000000003">74.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="72.299999999999997">72.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="58.799999999999997">58.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="67.400000000000006">67.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="63.100000000000001">63.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl82" x:num="67.799999999999997">67.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="67.099999999999994">67.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="69.400000000000006">69.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="63">63.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="71.599999999999994">71.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl85" x:num="37">37.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_A_Transductive_Approach_for_Video_Object_Segmentation_CVPR_2020_paper.pdf" target="_parent">CVPR2020</a></td>
    <td class="xl86" x:str><a href="https://github.com/&#10;microsoft/transductive-vos.pytorch" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>SAT</td>
    <td class="xl75" x:num="68.599999999999994">68.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="76">76.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="72.299999999999997">72.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl75" x:num="82.599999999999994">82.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="83.599999999999994">83.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="83.099999999999994">83.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="63.600000000000001">63.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="67.099999999999994">67.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="70.200000000000003">70.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="55.299999999999997">55.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="61.700000000000003">61.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl85" x:num="39">39.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_State-Aware_Tracker_for_Real-Time_Video_Object_Segmentation_CVPR_2020_paper.pdf" target="_parent">CVPR2020</a></td>
    <td class="xl65"></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>FEELVOS</td>
    <td class="xl75" x:num="69.099999999999994">69.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="74">74.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="71.5">71.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="55.200000000000003">55.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="60.5">60.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="57.799999999999997">57.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="81.099999999999994">81.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="82">82.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="81.700000000000003">81.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="1.96">2.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Voigtlaender_FEELVOS_Fast_End-To-End_Embedding_Learning_for_Video_Object_Segmentation_CVPR_2019_paper.pdf" target="_parent">CVPR2019</a></td>
    <td class="xl86" x:str><a href="https://github.com/tensorflow/models/tree/master/research/feelvos" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>A-GAME</td>
    <td class="xl75" x:num="67.200000000000003">67.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="72.700000000000003">72.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="70">70.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl75" x:num="82">82.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="82.200000000000003">82.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="82.099999999999994">82.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="66.099999999999994">66.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl82" x:num="67.799999999999997">67.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl82" x:num="60.799999999999997">60.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="14.285">14.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl87" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.pdf" target="_parent">CVPR2019</a></td>
    <td class="xl86" x:str><a href="https://github.com/joakimjohnander/agame-vos" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>DyeNet</td>
    <td class="xl75" x:num="65.799999999999997">65.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="70.5">70.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="68.200000000000003">68.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl66"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="0.42999999999999999">0.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://arxiv.org/abs/1803.04242" target="_parent">ECCV2018</a></td>
    <td class="xl65"></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>RGMP</td>
    <td class="xl75" x:num="64.799999999999997">64.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="68.599999999999994">68.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="66.700000000000003">66.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl79" x:num="81.5">81.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl79" x:num="82">82.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl79" x:num="81.75">81.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="7.6920000000000002">7.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1029.pdf" target="_parent">CVPR2018</a></td>
    <td class="xl86" x:str><a href="https://github.com/seoungwugoh/RGMP" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>RANet</td>
    <td class="xl75" x:num="63.200000000000003">63.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="68.200000000000003">68.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="65.700000000000003">65.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="53.399999999999999">53.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="57.189999999999998">57.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl78" x:num="55.299999999999997">55.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="85.5">85.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="85.400000000000006">85.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="85.5">85.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="30">30.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_RANet_Ranking_Attention_Network_for_Fast_Video_Object_Segmentation_ICCV_2019_paper.pdf" target="_parent">ICCV2019</a></td>
    <td class="xl86" x:str><a href="https://github.com/Storife/RANet" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>OnAVOS</td>
    <td class="xl75" x:num="61.600000000000001">61.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="69.099999999999994">69.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="65.349999999999994">65.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl75" x:num="86.099999999999994">86.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="84.900000000000006">84.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="85.5">85.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="0.10000000000000001">0.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://arxiv.org/pdf/1706.09364.pdf" target="_parent">BMCV2017</a></td>
    <td class="xl86" x:str><a href="https://github.com/Stocastico/OnAVOS" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>STCNN</td>
    <td class="xl75" x:num="58.700000000000003">58.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="64.599999999999994">64.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="61.649999999999999">61.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl75" x:num="83.5">83.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="83.799999999999997">83.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="83.799999999999997">83.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="3.8999999999999999">3.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Spatiotemporal_CNN_for_Video_Object_Segmentation_CVPR_2019_paper.pdf" target="_parent">CVPR2019</a></td>
    <td class="xl86" x:str><a href="https://github.com/longyin880815/STCNN" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>D3S</td>
    <td class="xl75" x:num="57.799999999999997">57.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="63.799999999999997">63.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="60.799999999999997">60.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl79" x:num="75.400000000000006">75.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl79" x:num="72.599999999999994">72.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="74">74.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="25">25.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Lukezic_D3S_-_A_Discriminative_Single_Shot_Segmentation_Tracker_CVPR_2020_paper.pdf" target="_parent">CVPR2020</a></td>
    <td class="xl86" x:str><a href="https://github.com/alanlukezic/d3s" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>OSVOS</td>
    <td class="xl75" x:num="56.600000000000001">56.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="63.899999999999999">63.9<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="60.25">60.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl75" x:num="79.799999999999997">79.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="80.599999999999994">80.6<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="80.189999999999998">80.2<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="0.10000000000000001">0.1<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Caelles_One-Shot_Video_Object_CVPR_2017_paper.pdf" target="_parent">CVPR2017</a></td>
    <td class="xl86" x:str><a href="https://github.com/kmaninis/OSVOS-PyTorch" target="_parent">Code</a></td>
   </tr>
   <tr height="22" style='height:16.50pt;'>
    <td class="xl74" height="22" style='height:16.50pt;' x:str>SiamMask</td>
    <td class="xl75" x:num="54.299999999999997">54.3<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="58.5">58.5<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="56.399999999999999">56.4<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl67"></td>
    <td class="xl75" x:num="71.700000000000003">71.7<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="67.799999999999997">67.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl75" x:num="69.75">69.8<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl68"></td>
    <td class="xl85" x:num="55">55.0<span style='mso-spacerun:yes;'>&nbsp;</span></td>
    <td class="xl86" x:str><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Fast_Online_Object_Tracking_and_Segmentation_A_Unifying_Approach_CVPR_2019_paper.pdf" target="_parent">CVPR2019</a></td>
    <td class="xl86" x:str><a href="https://github.com/foolwood/SiamMask" target="_parent">Code</a></td>
   </tr>
   <![if supportMisalignedColumns]>
    <tr width="0" style='display:none;'>
     <td width="136" style='width:102;'></td>
     <td width="57" style='width:43;'></td>
     <td width="57" style='width:43;'></td>
     <td width="57" style='width:43;'></td>
     <td width="57" style='width:43;'></td>
     <td width="42" style='width:32;'></td>
     <td width="57" style='width:43;'></td>
     <td width="109" style='width:82;'></td>
    </tr>
   <![endif]>
  </table>


### Evaluation metrics
- **mIoU**: The mean intersection over union averaged across objects and summed over all frames. 
- **J**   : The mIoU is evaluated on the full objects.
- **F**   : The mIoU is evaluated on the object boundaries.
- **J&F** : The global metric is the average of the J and F measures.


## Paper List

**CVPR2020**

- **TVOS:** Zhang, Yizhuo and Wu, Zhirong and Peng, Houwen and Lin, Stephen.<br>
"A Transductive Approach for Video Object Segmentation." [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_A_Transductive_Approach_for_Video_Object_Segmentation_CVPR_2020_paper.pdf) [[Code]](https://github.com/microsoft/transductive-vos.pytorch)

- **FRTM-VOS:** Robinson, Andreas and Lawin, Felix Jaremo and Danelljan, Martin and Khan, Fahad Shahbaz and Felsberg, Michael.<br>
"Learning Fast and Robust Target Models for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Robinson_Learning_Fast_and_Robust_Target_Models_for_Video_Object_Segmentation_CVPR_2020_paper.pdf) [[Code]](https://github.com/andr345/frtm-vos)

- **TAN-DTTM:** Huang, Xuhua and Xu, Jiarui and Tai, Yu-Wing and Tang, Chi-Keung.<br>
"Fast Video Object Segmentation With Temporal Aggregation Network and Dynamic Template Matching."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Fast_Video_Object_Segmentation_With_Temporal_Aggregation_Network_and_Dynamic_CVPR_2020_paper.pdf) [[Code]](https://github.com/XUHUAKing)

- **MuG:** Lu, Xiankai and Wang, Wenguan and Shen, Jianbing and Tai, Yu-Wing and Crandall, David J. and Hoi, Steven C. H..<br>
"Learning Video Object Segmentation From Unlabeled Videos."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Lu_Learning_Video_Object_Segmentation_From_Unlabeled_Videos_CVPR_2020_paper.pdf) [[Code]](https://github.com/carrierlxk/MuG)

- **SAT:** Chen, Xi and Li, Zuoxin and Yuan, Ye and Yu, Gang and Shen, Jianxin and Qi, Donglian.<br>
"State-Aware Tracker for Real-Time Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_State-Aware_Tracker_for_Real-Time_Video_Object_Segmentation_CVPR_2020_paper.pdf)

- **MA-Net:** Miao, Jiaxu and Wei, Yunchao and Yang, Yi.<br>
"Memory Aggregation Networks for Efficient Interactive Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Miao_Memory_Aggregation_Networks_for_Efficient_Interactive_Video_Object_Segmentation_CVPR_2020_paper.pdf)

- **D3S:** Lukezic, Alan and Matas, Jiri and Kristan, Matej.<bar>
"D3S - A Discriminative Single Shot Segmentation Tracker."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Lukezic_D3S_-_A_Discriminative_Single_Shot_Segmentation_Tracker_CVPR_2020_paper.pdf) [[Code]](https://github.com/alanlukezic/d3s)


**ICCV2019**

- **AD-Net** Yang, Zhao and Wang, Qiang and Bertinetto, Luca and Hu, Weiming and Bai, Song and Torr, Philip H. S.<bar>
"Anchor Diffusion for Unsupervised Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Anchor_Diffusion_for_Unsupervised_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/yz93/anchor-diff-VOS)

- **STM:** Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon Joo.<bar>
"Video Object Segmentation Using Space-Time Memory Networks."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.pdf) [[Code]](https://github.com/seoungwugoh/STM)

- **AGNN:** Wang, Wenguan and Lu, Xiankai and Shen, Jianbing and Crandall, David J. and Shao, Ling.<bar>
"Zero-Shot Video Object Segmentation via Attentive Graph Neural Networks."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Zero-Shot_Video_Object_Segmentation_via_Attentive_Graph_Neural_Networks_ICCV_2019_paper.pdf) [[Code]](https://github.com/carrierlxk/AGNN)

- **DMM-Net:** Zeng, Xiaohui and Liao, Renjie and Gu, Li and Xiong, Yuwen and Fidler, Sanja and Urtasun, Raquel.<bar>
"DMM-Net: Differentiable Mask-Matching Network for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Zeng_DMM-Net_Differentiable_Mask-Matching_Network_for_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/ZENGXH/DMM_Net)

- **AGSS-VOS:** Lin, Huaijia and Qi, Xiaojuan and Jia, Jiaya.<bar>
"AGSS-VOS: Attention Guided Single-Shot Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Lin_AGSS-VOS_Attention_Guided_Single-Shot_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/Jia-Research-Lab/AGSS-VOS)

- **RANet:** Wang, Ziqin and Xu, Jun and Liu, Li and Zhu, Fan and Shao, Ling.<bar>
"RANet: Ranking Attention Network for Fast Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_RANet_Ranking_Attention_Network_for_Fast_Video_Object_Segmentation_ICCV_2019_paper.pdf) [[Code]](https://github.com/Storife/RANet)

- **DTN:** Zhang, Lu and Lin, Zhe and Zhang, Jianming and Lu, Huchuan and He, You.<bar>
"Fast Video Object Segmentation via Dynamic Targeting Network."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Fast_Video_Object_Segmentation_via_Dynamic_Targeting_Network_ICCV_2019_paper.pdf) [[Code]](https://github.com/zhangludl/Code-for-DTN)

- **CapsuleVOS:** Duarte, Kevin and Rawat, Yogesh S. and Shah, Mubarak.<bar>
"CapsuleVOS: Semi-Supervised Video Object Segmentation Using Capsule Routing."[[Paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Duarte_CapsuleVOS_Semi-Supervised_Video_Object_Segmentation_Using_Capsule_Routing_ICCV_2019_paper.pdf) [[Code]](https://github.com/KevinDuarte/CapsuleVOS)

**CVPR2019**

- **MHP-VOS:** Xu, Shuangjie and Liu, Daizong and Bao, Linchao and Liu, Wei and Zhou, Pan.<bar>
"MHP-VOS: Multiple Hypotheses Propagation for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_MHP-VOS_Multiple_Hypotheses_Propagation_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/shuangjiexu/MHP-VOS)

- **STCNN:** Xu, Kai and Wen, Longyin and Li, Guorong and Bo, Liefeng and Huang, Qingming.<bar>
"Spatiotemporal CNN for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Spatiotemporal_CNN_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/longyin880815/STCNN)

- **AGS:** Wang, Wenguan and Song, Hongmei and Zhao, Shuyang and Shen, Jianbing and Zhao, Sanyuan and Hoi, Steven C. H. and Ling, Haibin.<bar>
"Learning Unsupervised Video Object Segmentation Through Visual Attention."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Learning_Unsupervised_Video_Object_Segmentation_Through_Visual_Attention_CVPR_2019_paper.pdf) [[Code]](https://github.com/wenguanwang/AGS)

- **COSNet:** Lu, Xiankai and Wang, Wenguan and Ma, Chao and Shen, Jianbing and Shao, Ling and Porikli, Fatih.<bar>
"See More, Know More: Unsupervised Video Object Segmentation With Co-Attention Siamese Networks."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Lu_See_More_Know_More_Unsupervised_Video_Object_Segmentation_With_Co-Attention_CVPR_2019_paper.pdf) [[Code]](https://github.com/carrierlxk/COSNet)


- **IVS:** Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon Joo.<bar>
"Fast User-Guided Video Object Segmentation by Interaction-And-Propagation Networks."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Oh_Fast_User-Guided_Video_Object_Segmentation_by_Interaction-And-Propagation_Networks_CVPR_2019_paper.pdf) [[Code]](https://github.com/seoungwugoh/ivs-demo)

- **RVOS:** Ventura, Carles and Bellver, Miriam and Girbau, Andreu and Salvador, Amaia and Marques, Ferran and Giro-i-Nieto, Xavier.<bar>
"RVOS: End-To-End Recurrent Network for Video Object Segmentation." [[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Ventura_RVOS_End-To-End_Recurrent_Network_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/imatge-upc/rvos)

- **BubbleNets:** Griffin, Brent A. and Corso, Jason J.<bar>
"BubbleNets: Learning to Select the Guidance Frame in Video Object Segmentation by Deep Sorting Frames."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Griffin_BubbleNets_Learning_to_Select_the_Guidance_Frame_in_Video_Object_CVPR_2019_paper.pdf) [[Code]](https://github.com/griffbr/BubbleNets)

- **AGAME:** Johnander, Joakim and Danelljan, Martin and Brissman, Emil and Khan, Fahad Shahbaz and Felsberg, Michael.<bar>
"A Generative Appearance Model for End-To-End Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/joakimjohnander/agame-vos)

- **FEELVOS:** Voigtlaender, Paul and Chai, Yuning and Schroff, Florian and Adam, Hartwig and Leibe, Bastian and Chen, Liang-Chieh.<bar>
"FEELVOS: Fast End-To-End Embedding Learning for Video Object Segmentation."[[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Voigtlaender_FEELVOS_Fast_End-To-End_Embedding_Learning_for_Video_Object_Segmentation_CVPR_2019_paper.pdf) [[Code]](https://github.com/kim-younghan/FEELVOS)


## Datasets

- **SAIL-VOS:** Hu, Yuan-Ting and Chen, Hong-Shuo and Hui, Kexin and Huang, Jia-Bin and Schwing, Alexander G.<bar>
"SAIL-VOS: Semantic Amodal Instance Level Video Object Segmentation - A Synthetic Dataset and Baselines." CVPR2019. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Hu_SAIL-VOS_Semantic_Amodal_Instance_Level_Video_Object_Segmentation_-_A_CVPR_2019_paper.pdf) [[website]](http://sailvos.web.illinois.edu/_site/index.html)

- **SegTrack v2:** Fuxin Li and Taeyoung Kim and Ahmad Humayun and David Tsai and James M. Rehg.<bar>
" Video Segmentation by Tracking Many Figure-Ground Segments."[[Paper]](https://web.engr.oregonstate.edu/~lif/SegTrack2/segtrack2_cameraready.pdf) [[website]](https://web.engr.oregonstate.edu/~lif/SegTrack2/dataset.html)

- **DAVIS:** "Densely Annotated Video Segmentation."[[website]](https://davischallenge.org/)

- **YouTube-VOS:** "A Large-Scale Benchmark for Video Object Segmentation."[[website]](https://youtube-vos.org/)
